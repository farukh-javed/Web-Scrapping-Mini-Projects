{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.dawn.com/sport\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "articles = soup.find_all('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = []\n",
    "\n",
    "for article in articles:\n",
    "    news_item = {}\n",
    "\n",
    "    headline_tag = article.find('h2', class_='story__title')\n",
    "    if headline_tag and headline_tag.a:\n",
    "        news_item['headline'] = headline_tag.a.get_text(strip=True)\n",
    "        link = headline_tag.a['href']\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    description_tag = article.find('div', class_='story__excerpt')\n",
    "    if description_tag:\n",
    "       news_item['description'] = description_tag.get_text(strip=True)\n",
    "    else:\n",
    "       'No description available'\n",
    "\n",
    "    image_tag = article.find('div', class_='media__item')\n",
    "    if image_tag and image_tag.img:\n",
    "        news_item['image'] = image_tag.img['src']\n",
    "    else:\n",
    "        news_item['image'] = 'No image available'\n",
    "\n",
    "    response1 = requests.get(link)\n",
    "    soup1 = BeautifulSoup(response1.content, 'html5lib')\n",
    "\n",
    "    content = soup1.find_all('p')\n",
    "    full_text = \"\\n\".join([para.get_text(strip=True) for para in content])\n",
    "    if full_text:\n",
    "       news_item['full_text'] = full_text\n",
    "    else:\n",
    "       'No content available'\n",
    "\n",
    "    news_data.append(news_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dawn_sports_news.json', 'w+') as json_file:\n",
    "    json.dump(news_data, json_file, indent=4)\n",
    "\n",
    "print(\"Scraping complete. Data saved to 'dawn_sports_news.json'.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
